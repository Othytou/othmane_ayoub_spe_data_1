{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74a1069",
   "metadata": {},
   "source": [
    "# Data Scraping: weather records üå°Ô∏è\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a476d9",
   "metadata": {},
   "source": [
    "## Step 1 : Explore the web page üåê\n",
    "***\n",
    "\n",
    "[Wikipedia link: List of weather records](https://en.wikipedia.org/wiki/List_of_weather_records)\n",
    "\n",
    "\n",
    "\n",
    "**This is the table we are interested in**\n",
    "\n",
    "<div>\n",
    "    <img src='https://raw.githubusercontent.com/Selimmmm/spe1/1eb8695ee9f14d62b127789817a86889db14aa34/projets/projet_III/images/9_img_table_countries.png' width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "## Step 2 : Explore the page source üñ•Ô∏è\n",
    "***\n",
    "\n",
    "\n",
    "**This is the table and its HTML code (file available at: `code/table_countries.html`)**\n",
    "\n",
    "\n",
    "<div>\n",
    "    <img src='https://raw.githubusercontent.com/Selimmmm/spe1/1eb8695ee9f14d62b127789817a86889db14aa34/projets/projet_III/images/code_img_table_countries.png' width=\"800\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879cf012",
   "metadata": {},
   "source": [
    "## Step 3 : Locate useful data üíæ\n",
    "***\n",
    "\n",
    "\n",
    "#### Page source of a row from the table of interest\n",
    "\n",
    "```html\n",
    "<tr>\n",
    "    <td><span class=\"flagicon\"><span class=\"mw-image-border\"\n",
    "                  typeof=\"mw:File\"><span><img alt=\"\"\n",
    "                         src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Flag_of_Panama.svg/23px-Flag_of_Panama.svg.png\"\n",
    "                         decoding=\"async\"\n",
    "                         width=\"23\"\n",
    "                         height=\"15\"\n",
    "                         class=\"mw-file-element\"\n",
    "                         srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Flag_of_Panama.svg/35px-Flag_of_Panama.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Flag_of_Panama.svg/45px-Flag_of_Panama.svg.png 2x\"\n",
    "                         data-file-width=\"900\"\n",
    "                         data-file-height=\"600\"></span></span>&nbsp;</span><a href=\"/wiki/Panama\"\n",
    "           title=\"Panama\">Panama</a>\n",
    "    </td>\n",
    "    <td style=\"background: #FF0A00; color:#FFFFFF; font-size:85%;\">40.0&nbsp;¬∞C (104.0&nbsp;¬∞F)\n",
    "    </td>\n",
    "    <td><a href=\"/wiki/San_Francisco,_Panam%C3%A1\"\n",
    "           title=\"San Francisco, Panam√°\">San Francisco</a>\n",
    "    </td>\n",
    "    <td><span data-sort-value=\"000000001998-03-20-0000\"\n",
    "              style=\"white-space:nowrap\">20 March 1998</span><sup id=\"cite_ref-ETESA_168-0\"\n",
    "             class=\"reference\"><a href=\"#cite_note-ETESA-168\">[161]</a></sup>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "```\n",
    "\n",
    "#### Selection : \n",
    "\n",
    "- Second `<td>` tag contains : \n",
    "    - the temperature data point ‚ú¥Ô∏è (as text of the tag)\n",
    "    - An interesting color we can re-use ! üé® (as the background-color of the tag)\n",
    "\n",
    "\n",
    "- Third `<td>` tag contains the url of the wikipedia page of the place \n",
    "    - We'll need the GPS coordinates stored on this page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e833f849",
   "metadata": {},
   "source": [
    "## Step 4 : Code ü§ñ\n",
    "***\n",
    "\n",
    "\n",
    "### A. Obtain the page source of the page\n",
    "- `requests` is a library : code already written we can re-use\n",
    "- `requests` will be used to send an HTTP request to wikipedia \n",
    "- The response will contain the page source of the web page\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "529d5b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code is: 200\n",
      "As of now, everything's is working.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_weather_records\"\n",
    "\n",
    "response = requests.get(url)\n",
    "status_code = response.status_code\n",
    "print(f\"Status code is: {status_code}\")\n",
    "\n",
    "if status_code == 200:\n",
    "    print(\"As of now, everything's is working.\")\n",
    "else:\n",
    "    print(\"Some debugging has to be done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54352ab5",
   "metadata": {},
   "source": [
    "**The `text` attribute of the `response` object contains page source**.<br>\n",
    "**We display the first 100 characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "24899236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-la\n"
     ]
    }
   ],
   "source": [
    "print(response.text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337aafa4",
   "metadata": {},
   "source": [
    "\n",
    "### B. Parse the page source\n",
    "***\n",
    "- An HTML page source has a tree structure\n",
    "- Trees are very specific data structure \n",
    "- We can use the library `bs4` and its wonderful `BeautifulSoup` to get the data we need from the HTML source : the table\n",
    "\n",
    "**<div style=\"color:red\">There are multiple tables with classes `wikitable sortable` !! Be sure to select the right one</div>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a8944b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 table with `wikitable sortable` class\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(response.text)\n",
    "print(len(soup.find_all(\"table\", class_=\"wikitable sortable\")), \"table with `wikitable sortable` class\")\n",
    "table = soup.find(\"table\", class_=\"wikitable sortable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da8bae",
   "metadata": {},
   "source": [
    "### C. Extract the data needed\n",
    "***\n",
    "\n",
    "[Some useful information about HTML tables](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/table)<br>\n",
    "***(developer.mozilla.org is one of most useful website when dealing with frontend considerations)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "24eb136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all  `tr` tags \n",
    "# (except the first one as it is the header)\n",
    "rows = table.find_all(\"tr\")[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaad4bd",
   "metadata": {},
   "source": [
    "**Example: get temperature data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a7d77ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Td ###\n",
      "<td style=\"background: #840000; color:#FFFFFF; font-size:85%;\">50.4¬†¬∞C (122.7¬†¬∞F)\n",
      "</td>\n",
      "\n",
      "### Td -> Text ###\n",
      "50.4¬†¬∞C (122.7¬†¬∞F)\n",
      "\n",
      "\n",
      "### Td -> Style ###\n",
      "background: #840000; color:#FFFFFF; font-size:85%;\n"
     ]
    }
   ],
   "source": [
    "row_example = rows[12]\n",
    "\n",
    "tds_example = row_example.find_all(\"td\")\n",
    "\n",
    "print('### Td ###')\n",
    "print(tds_example[1])\n",
    "\n",
    "\n",
    "print('\\n### Td -> Text ###')\n",
    "print(tds_example[1].text)\n",
    "\n",
    "print('\\n### Td -> Style ###')\n",
    "print(tds_example[1].get(\"style\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9dbd77",
   "metadata": {},
   "source": [
    "**Example: get url of page of location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d4d931c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Td -> a ###\n",
      "<a href=\"/wiki/Agadir\" title=\"Agadir\">Agadir</a>\n",
      "\n",
      "### Td -> a -> href ###\n",
      "/wiki/Agadir\n"
     ]
    }
   ],
   "source": [
    "print('### Td -> a ###')\n",
    "\n",
    "print(tds_example[2].find(\"a\"))\n",
    "\n",
    "\n",
    "print('\\n### Td -> a -> href ###')\n",
    "\n",
    "print(tds_example[2].find(\"a\").get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f861e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for row in rows:\n",
    "\n",
    "    # All cells\n",
    "    tds = row.find_all(\"td\")\n",
    "\n",
    "    # Temperature\n",
    "    temperature_text = tds[1].text\n",
    "\n",
    "    # Style to get background\n",
    "    style = tds[1].get(\"style\")\n",
    "\n",
    "    # Color (background)\n",
    "    color_code = style.split(\";\")[0].replace(\"background: \", \"\")\n",
    "\n",
    "    # Url page of location\n",
    "    a = tds[2].find(\"a\")\n",
    "    \n",
    "    \n",
    "    if a is not None:\n",
    "        url_suffix = a.get(\"href\")\n",
    "    else:\n",
    "        url_suffix = None\n",
    "    raw_data.append(\n",
    "        {\n",
    "            \"temperature_text\":temperature_text,\n",
    "            \"color_code\":color_code,\n",
    "            \"url_suffix\":url_suffix\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e8e8e6",
   "metadata": {},
   "source": [
    "### D. Clean the data\n",
    "***\n",
    "\n",
    "- We rely on `pandas` which gives us a high ligh level API to manipulate tabular data <br>\n",
    "\n",
    "**(high level mean it gives us the right to be lazy: complex operations can often be managed with a few lines of code)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "407b254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f8399e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_temperature_in_celsius(temp_text):\n",
    "    \"\"\"This functions extract the temperature in celsius and convert to float\"\"\"\n",
    "    temp = temp_text.split(\"¬∞\")[0]\n",
    "    temp = temp.strip()\n",
    "    return float(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4170c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temperature\"] = df.temperature_text.map(extract_temperature_in_celsius)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c835bef",
   "metadata": {},
   "source": [
    "### E. Coordinates scraping \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c716f7",
   "metadata": {},
   "source": [
    "**Select only the valid ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b254c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_suffixes = df.url_suffix.tolist()\n",
    "\n",
    "url_suffixes_page_exist = []\n",
    "for url_suffix in  url_suffixes:\n",
    "    if url_suffix is None:\n",
    "        url_suffixes_page_exist.append(None)\n",
    "    elif url_suffix.startswith(\"/wiki\"):\n",
    "        url_suffixes_page_exist.append(url_suffix)\n",
    "    else:\n",
    "        url_suffixes_page_exist.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee28e18c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url_suffixes_page_exist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m url_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://en.wikipedia.org\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m coordinates \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url_suffix \u001b[38;5;129;01min\u001b[39;00m \u001b[43murl_suffixes_page_exist\u001b[49m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(url_suffix)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'url_suffixes_page_exist' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "url_prefix = \"https://en.wikipedia.org\"\n",
    "\n",
    "coordinates = []\n",
    "for url_suffix in url_suffixes_page_exist:\n",
    "    print(url_suffix)\n",
    "    try:\n",
    "        url_location = url_prefix + url_suffix\n",
    "        response_location = requests.get(url_location)\n",
    "        coords = BeautifulSoup(response_location.text).find(id=\"coordinates\")\n",
    "        if coords is not None:\n",
    "            lat, long = coords.find(\"span\", class_=\"latitude\").text,coords.find(\"span\", class_=\"longitude\").text\n",
    "        else:\n",
    "            lat, long = None, None\n",
    "            \n",
    "        \n",
    "    except:\n",
    "        lat, long = None, None\n",
    "    \n",
    "    coordinates.append((lat, long))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1c83c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert we have 146 (not to break alignment with our DataFrame)\n",
    "assert len(coordinates) == 146\n",
    "\n",
    "df[\"coordinates_str\"] = coordinates\n",
    "\n",
    "# df.to_pickle(\"data/df_with_coordinates_str.pk\")\n",
    "# df.to_csv(\"data/df_with_coordinates_str.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1b55dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kudos to ChatGPT \n",
    "# Explain from showing onto the page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcebf00f",
   "metadata": {},
   "source": [
    "### F. Ask ChatGPT to finish the job\n",
    "***\n",
    "- Coordinates are not in a decimal format: we need it for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "68023de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(\"data/df_with_coordinates_str.pk\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e3b2ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For asking nicely to ChatGPT : \n",
    "### print(\"\\n\".join(df.coordinates_str.astype(str).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c00b3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_decimal(dms):\n",
    "    \"\"\"\n",
    "    Convert DMS (degrees, minutes, seconds) string to decimal degrees. Minutes and seconds are optional and may include decimals.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Match the degrees, optional fractional minutes, and optional fractional seconds with N, S, E, or W\n",
    "    pattern = re.compile(r'(\\d{1,3})¬∞(\\d{1,2}(?:\\.\\d+)?‚Ä≤)?(?:(\\d{1,2}(?:\\.\\d+)?)‚Ä≥)?([NSEW])')\n",
    "    match = pattern.search(dms)\n",
    "    \n",
    "    if not match:\n",
    "        print(dms)\n",
    "        raise ValueError(\"Input does not match DMS format\")\n",
    "    \n",
    "    degrees, minutes, seconds, direction = match.groups()\n",
    "    \n",
    "    # Convert strings to integers or floats\n",
    "    degrees = int(degrees)\n",
    "    minutes = float(minutes.rstrip('‚Ä≤')) if minutes else 0.0\n",
    "    seconds = float(seconds.rstrip('‚Ä≥')) if seconds else 0.0\n",
    "    \n",
    "    # Convert to decimal degrees\n",
    "    decimal = degrees + minutes / 60 + seconds / 3600\n",
    "    \n",
    "    # Account for direction South or West\n",
    "    if direction in 'SW':\n",
    "        decimal = -decimal\n",
    "    \n",
    "    return decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a0b961c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lat\"] = df[\"coordinates_str\"].map(\n",
    "    lambda lat_long: dms_to_decimal(lat_long[0]) if lat_long[0] is not None else None\n",
    ")\n",
    "df[\"long\"] = df[\"coordinates_str\"].map(\n",
    "    lambda lat_long: dms_to_decimal(lat_long[1]) if lat_long[1] is not None else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b1f720e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(\"data/df_with_coordinates_cleaned.pk\")\n",
    "# df.to_csv(\"data/df_with_coordinates_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897d1f7",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "# Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336f630",
   "metadata": {},
   "source": [
    "**Using pandas (but we loose the color from style**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "db61484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/7zryq8v115v8hjpz3_522bvm0000gn/T/ipykernel_9589/4136137395.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), flavor=\"lxml\")[0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_weather_records\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text)\n",
    "table = soup.find(\"table\", class_=\"wikitable sortable\")\n",
    "# df = pd.read_html(str(table), flavor=\"lxml\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29064baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Town/Location</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>51.3¬†¬∞C (124.3¬†¬∞F)</td>\n",
       "      <td>Ouargla, Ouargla Province</td>\n",
       "      <td>5 July 2018[22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Botswana</td>\n",
       "      <td>44.0¬†¬∞C (111.2¬†¬∞F)</td>\n",
       "      <td>Maun</td>\n",
       "      <td>7 January 2016[23][24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>47.2¬†¬∞C (117.0¬†¬∞F)</td>\n",
       "      <td>Dori</td>\n",
       "      <td>1984[25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chad</td>\n",
       "      <td>48.0¬†¬∞C (118.4¬†¬∞F)</td>\n",
       "      <td>Faya-Largeau</td>\n",
       "      <td>25 May 2023[26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comoros</td>\n",
       "      <td>36.0¬†¬∞C (96.8¬†¬∞F)</td>\n",
       "      <td>Hahaya International Airport</td>\n",
       "      <td>15 November 2017[27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>French Guiana</td>\n",
       "      <td>38.0¬†¬∞C (100.4¬†¬∞F)</td>\n",
       "      <td>Saint-Laurent-du-Maroni</td>\n",
       "      <td>27 September 2016[145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Paraguay</td>\n",
       "      <td>46.2¬†¬∞C (115.2¬†¬∞F)</td>\n",
       "      <td>Las Palmas</td>\n",
       "      <td>10 December 2022[180]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Peru</td>\n",
       "      <td>41.6¬†¬∞C (106.9¬†¬∞F)</td>\n",
       "      <td>I√±apari</td>\n",
       "      <td>7 October 2023[181]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>44.0¬†¬∞C (111.2¬†¬∞F)</td>\n",
       "      <td>Paysand√∫, Paysand√∫ Department Florida, Florida...</td>\n",
       "      <td>20 January 1943[182][183] 14 January 2022[184]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>43.6¬†¬∞C (110.5¬†¬∞F)</td>\n",
       "      <td>Santa Ana de Coro, Falc√≥n</td>\n",
       "      <td>29 April 2015[142]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country/Region         Temperature  \\\n",
       "0          Algeria  51.3¬†¬∞C (124.3¬†¬∞F)   \n",
       "1         Botswana  44.0¬†¬∞C (111.2¬†¬∞F)   \n",
       "2     Burkina Faso  47.2¬†¬∞C (117.0¬†¬∞F)   \n",
       "3             Chad  48.0¬†¬∞C (118.4¬†¬∞F)   \n",
       "4          Comoros   36.0¬†¬∞C (96.8¬†¬∞F)   \n",
       "..             ...                 ...   \n",
       "141  French Guiana  38.0¬†¬∞C (100.4¬†¬∞F)   \n",
       "142       Paraguay  46.2¬†¬∞C (115.2¬†¬∞F)   \n",
       "143           Peru  41.6¬†¬∞C (106.9¬†¬∞F)   \n",
       "144        Uruguay  44.0¬†¬∞C (111.2¬†¬∞F)   \n",
       "145      Venezuela  43.6¬†¬∞C (110.5¬†¬∞F)   \n",
       "\n",
       "                                         Town/Location  \\\n",
       "0                            Ouargla, Ouargla Province   \n",
       "1                                                 Maun   \n",
       "2                                                 Dori   \n",
       "3                                         Faya-Largeau   \n",
       "4                         Hahaya International Airport   \n",
       "..                                                 ...   \n",
       "141                            Saint-Laurent-du-Maroni   \n",
       "142                                         Las Palmas   \n",
       "143                                            I√±apari   \n",
       "144  Paysand√∫, Paysand√∫ Department Florida, Florida...   \n",
       "145                          Santa Ana de Coro, Falc√≥n   \n",
       "\n",
       "                                               Date  \n",
       "0                                   5 July 2018[22]  \n",
       "1                            7 January 2016[23][24]  \n",
       "2                                          1984[25]  \n",
       "3                                   25 May 2023[26]  \n",
       "4                              15 November 2017[27]  \n",
       "..                                              ...  \n",
       "141                          27 September 2016[145]  \n",
       "142                           10 December 2022[180]  \n",
       "143                             7 October 2023[181]  \n",
       "144  20 January 1943[182][183] 14 January 2022[184]  \n",
       "145                              29 April 2015[142]  \n",
       "\n",
       "[146 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0039f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No coordinates found.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"The coordinates are 31¬∞57‚Ä≤N 5¬∞19‚Ä≤E.\"\n",
    "pattern = re.compile(r'(\\d{1,3})¬∞(\\d{1,2})‚Ä≤([NS]) (\\d{1,3})¬∞(\\d{1,2})‚Ä≤([EW])')\n",
    "\n",
    "match = pattern.search(response_location.text)\n",
    "if match:\n",
    "    print(\"Found coordinates:\", match.group())\n",
    "else:\n",
    "    print(\"No coordinates found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c0ca9",
   "metadata": {},
   "source": [
    "### No fractionnal seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f769d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_decimal(dms):\n",
    "    \"\"\"\n",
    "    Convert DMS (degrees, minutes, seconds) string to decimal degrees. Seconds are optional.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Match the degrees, minutes, and optional seconds with optional leading zeros and N, S, E, or W\n",
    "    pattern = re.compile(r'(\\d{1,3})¬∞(\\d{1,2})‚Ä≤(?:(\\d{1,2})‚Ä≥)?([NSEW])')\n",
    "    match = pattern.search(dms)\n",
    "    \n",
    "    if not match:\n",
    "        print(dms)\n",
    "        raise ValueError(\"Input does not match DMS format\") \n",
    "        # return None\n",
    "    \n",
    "    degrees, minutes, seconds, direction = match.groups()\n",
    "    \n",
    "    # Convert strings to integers\n",
    "    degrees = int(degrees)\n",
    "    minutes = int(minutes)\n",
    "    seconds = int(seconds) if seconds else 0\n",
    "    \n",
    "    # Convert to decimal degrees\n",
    "    decimal = degrees + minutes / 60 + seconds / 3600\n",
    "    \n",
    "    # Account for direction South or West\n",
    "    if direction in 'SW':\n",
    "        decimal = -decimal\n",
    "    \n",
    "    return decimal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69306d5",
   "metadata": {},
   "source": [
    "## Fractionnal seconds but no minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b60c48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_decimal(dms):\n",
    "    \"\"\"\n",
    "    Convert DMS (degrees, minutes, seconds) string to decimal degrees. Seconds are optional and may include decimals.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Match the degrees, minutes, and optional fractional seconds with optional leading zeros and N, S, E, or W\n",
    "    pattern = re.compile(r'(\\d{1,3})¬∞(\\d{1,2})‚Ä≤(?:(\\d{1,2}(?:\\.\\d+)?)‚Ä≥)?([NSEW])')\n",
    "    match = pattern.search(dms)\n",
    "    \n",
    "    if not match:\n",
    "        print(dms)\n",
    "        raise ValueError(\"Input does not match DMS format\")\n",
    "    \n",
    "    degrees, minutes, seconds, direction = match.groups()\n",
    "    \n",
    "    # Convert strings to integers or floats\n",
    "    degrees = int(degrees)\n",
    "    minutes = int(minutes)\n",
    "    seconds = float(seconds) if seconds else 0.0\n",
    "    \n",
    "    # Convert to decimal degrees\n",
    "    decimal = degrees + minutes / 60 + seconds / 3600\n",
    "    \n",
    "    # Account for direction South or West\n",
    "    if direction in 'SW':\n",
    "        decimal = -decimal\n",
    "    \n",
    "    return decimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826759cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_specific_name_2",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
